# 30 Nano Banana Issues FIXED! 30 Pro Tips You Can't Afford to Miss ðŸš€

## Metadata
- **Source**: User provided transcript
- **Extraction Date**: 2025-10-01
- **Video Duration**: N/A
- **Upload Date**: N/A
- **Channel**: AI in Action
- **Topics**: AI Image Generation > Gemini 2.5 Flash Image (Nano Banana), Character Consistency, Prompt Engineering
- **Knowledge Level**: Intermediate to Advanced
- **Prerequisites**: Basic understanding of image generation, photography terminology (aperture, shutter speed, etc.)
- **Key Tools/Technologies**: Gemini 2.5 Flash Image (Nano Banana), Midjourney, Canva, Google Veo 3, Luma Dream Machine, Runway, Kling, Hailuo, GPT-4, Claude, Photoshop

## Core Concepts

### Nano Banana (Gemini 2.5 Flash Image) Design Philosophy
- **Official Name**: "Gemini 2.5 Flash Image"
- **Optimization**: "This tool was optimized for speed, efficiency, and mobile users. It prioritizes rapid generation over maximum fidelity"
- **Core Strength**: "the most powerful high-speed consistency engine we have ever had access to"
- **Intended Purpose**: "a highly specialized, high-speed consistency engine"
- **Key Weakness**: "deliberate engineering choice" - speed over fidelity
- **Related Concepts**: Speed-fidelity tradeoff, mobile optimization

### Real-Time Zero-Shot LoRA Concept
- **Definition**: "The reason Nanobanana is so good at this can be thought of as a real time zeroot Laura. Normally, you'd have to train a custom Laura model on dozens of images to get character consistency. Nano Banana does it instantly from a single reference image"
- **Mechanism**: "It creates a temporary implicit model of your subject's key features, but this model is temporary and can be corrupted by new prompts"
- **Key Property**: Instant consistency from single reference vs. traditional LoRA training requiring dozens of images
- **Related Concepts**: LoRA models, character consistency, implicit modeling

### Technical Metadata Language
- **Core Principle**: "It was trained on millions of photos with all their technical metadata. So using that technical language isn't a suggestion. It's a coordinate pointing the model directly to the visuals you want"
- **Purpose**: "This is how we stop the model from interpreting and start making it execute"
- **Philosophy**: Precision over ambiguity in prompting
- **Related Concepts**: Camera metadata, EXIF data, technical specifications

### Semantic Positive Prompting
- **Definition**: "Nano Banana gets confused by negative commands like no cars or no rain. Instead, you must affirmatively describe the scene you do want"
- **Official Source**: "recommended directly by Google's own guides"
- **Key Property**: Model cannot process negative instructions effectively
- **Related Concepts**: Affirmative prompting, negative space description

### Consistency Drift
- **Definition**: "the main source of consistency drift where your character's face or the image quality just melts away after three or four edits"
- **Cause**: Accumulated artifacts and degraded context over iterative edits
- **Key Property**: Progressive quality loss in conversational editing
- **Related Concepts**: Context degradation, artifact accumulation

### Conversational Branching
- **Definition**: "When you get a result, instead of continuing the chat, go back and edit a previous prompt to generate a new variation. This creates a branch in your conversation timeline"
- **Purpose**: A/B testing without losing main edit history
- **Use Cases**: "perfect for AB testing creative ideas, exploring different lighting, or storyboarding alternate scenes"
- **Related Concepts**: Version control, parallel editing paths

### Digital Character Sheet
- **Definition**: "Start by generating one perfect highquality front-facing portrait of your character. This is your master reference"
- **Complete Form**: "This collection of orthogonal views is your character sheet. It gives you consistent visual data of your character from every angle for all future generations"
- **Components**: Front, side, and back views
- **Purpose**: Anchor for all future character generations
- **Related Concepts**: Orthogonal views, master reference, character consistency

### Multi-Image Reference Pattern
- **Core Mechanism**: "Upload both your master character portrait for identity and a separate reference image for the pose or environment for context"
- **Key Separation**: "This separates the task of identity from the task of action, giving you way more accuracy"
- **Applications**: Poses, group shots, prop consistency, style transfer
- **Related Concepts**: Task separation, reference-based generation

### Hybrid Tool Chain Philosophy
- **Core Principle**: "The future of AI art isn't one perfect tool. It's the curated AI toolkit, and it's mastering the art of making many tools work as one"
- **Strategy**: "build an intelligent hybrid tool chain around it. Combining its consistency with Midjourney's creativity and Photoshop's outpainting"
- **Implication**: No single AI tool is complete; professional workflow requires multi-tool integration
- **Related Concepts**: Pipeline optimization, tool specialization

## Procedures & Techniques

### Tip 1: Specify Camera, Lens, and Aperture

**Purpose**: Control depth of field, background compression, and bokeh with precision

**Bad Approach**: "Stop using vague terms like blurry background. That's ambiguous"

**Good Example**: "captured with an 85mm portrait lens at f1.8"

**Result**: "This tells the AI the exact depth of field, background compression, and bokeh effect you require"

**Prerequisites**: Understanding of camera optics, aperture effects

**Expected Outcome**: Precise optical characteristics matching specified hardware

### Tip 2: Use Cinematic Shot Composition

**Purpose**: "Control the frame using established film making language. This gives the AI unambiguous instructions on how to compose the scene"

**Bad Approach**: "Don't just say from below"

**Good Examples**:
- "ultra wide low angle shot from worm's eye view"
- "close-up 3/4 portrait"
- "medium shot"
- "bird's eye view"

**Prerequisites**: Knowledge of cinematography terminology

**Expected Outcome**: Precise framing matching film industry standards

### Tip 3: Command Lighting with Technical Language

**Purpose**: Define lighting setup to control mood completely

**Bad Approach**: "Good lighting means nothing"

**Good Examples**:
- "threepoint softbox setup" - clean studio look
- "soft golden hour light streaming through a window" - natural warm scene
- "vibrant pink, purple, and electric blue neon lights" - cyberpunk aesthetic

**Prerequisites**: Understanding of lighting setups and their effects

**Expected Outcome**: Specific mood and atmosphere from defined lighting configuration

### Tip 4: Reference Film Genres and Artistic Styles

**Purpose**: "guides the overall aesthetic by telling the model which visual conventions to pull from"

**Examples**:
- "film noir style, high contrast, moody and cinematic aesthetic"
- "sci-fi aesthetic with transparent lines and a galaxy backdrop"

**Prerequisites**: Familiarity with visual conventions of different genres

**Expected Outcome**: Consistent genre-specific aesthetic

### Tip 5: Use Semantic Positive Prompting

**Purpose**: Avoid model confusion from negative instructions

**Official Source**: "recommended directly by Google's own guides"

**Bad Prompt**: "a street with no cars"

**Good Prompt**: "An empty deserted street with no signs of traffic"

**Principle**: "This gives the AI a clear, positive instruction to execute"

**Prerequisites**: Understanding of affirmative description

**Expected Outcome**: Accurate rendering of desired negative space

### Tip 6: Control Motion with Shutter Speed Language

**Purpose**: Show or freeze motion using camera settings

**For Motion Blur**: "ask for a high shutter speed capturing the motion of people in cars as streaks of light, which mimics a long exposure"

**To Freeze Action**: "specify a fast shutter speed"

**Prerequisites**: Understanding of shutter speed effects on motion

**Expected Outcome**: Controlled motion representation

### Tip 7: Define Color Palettes and Temperature

**Purpose**: Control color grading with precision

**Examples**:
- "a vibrant color palette"
- "desaturated colors"
- "a warm color temperature"
- Technical: "Correct white balance to neutral daylight. 6500K"

**Prerequisites**: Color theory, white balance understanding

**Expected Outcome**: Specific color grading matching description

### Tip 8: Layer Specific Textural Details

**Purpose**: "This boosts realism. Guide the model on what surfaces to render in high detail"

**Examples**:
- "emphasizing key textures and details"
- "water droplets on skin and hair"
- "intricate panels and glowing accents"

**Prerequisites**: Understanding of material properties and surface detail

**Expected Outcome**: Enhanced realism in specified textures

### Tip 9: Combine Everything into Master Prompt

**Purpose**: Maximize control by layering all technical commands

**Master Prompt Template**:
"a photorealistic [shot type] of [subject] captured with a [camera lens details]. The scene is illuminated by [lighting description] creating a [mood/atmosphere] in the style of [film genre]. The color palette is [color description] with a focus on [key textures]"

**Prerequisites**: Mastery of Tips 1-8

**Expected Outcome**: Comprehensive control over all image aspects

### Tip 10: Use Incremental Single-Purpose Edits

**Purpose**: Prevent model overwhelm and maintain quality

**Rule**: "Never ever try to change multiple complex things in one prompt"

**Bad Prompt**: "Change the background to a beach. Make her smile and adjust the lighting to sunset"
- **Why It Fails**: "The model will get overwhelmed and give you a blended low-quality mess"

**Good Workflow** (sequential):
1. "Change the background to a beautiful beach"
2. "Now make her smile naturally"
3. "Finally, adjust the lighting to a warm sunset golden hour"

**Principle**: "This atomic approach is a core best practice"

**Prerequisites**: Patience, workflow planning

**Expected Outcome**: Higher quality results without degradation

### Tip 11: Execute the Fidelity Reset

**Purpose**: Clear artifact accumulation and restore image quality

**When to Use**: "After a long chain of edits, you'll see the image quality degrade as artifacts build up"

**Workflow**:
1. "download the last good, highquality version of your image"
2. "start a completely new chat session"
3. "upload that downloaded image as a fresh baseline"
4. "provide a new consolidated prompt for the next change"

**Result**: "This forces the model to reanalyze the highfidelity source, clearing its memory of the previous degraded steps and preventing further drift"

**Prerequisites**: Recognizing quality degradation, managing multiple chat sessions

**Expected Outcome**: Restored image quality, clean editing slate

### Tip 12: Use Conversational Branching

**Purpose**: Test variations without losing main edit history

**Method**: "When you get a result, instead of continuing the chat, go back and edit a previous prompt to generate a new variation"

**Result**: "This creates a branch in your conversation timeline"

**Use Cases**: "perfect for AB testing creative ideas, exploring different lighting, or storyboarding alternate scenes without losing your main edit history"

**Prerequisites**: Understanding of conversation interface mechanics

**Expected Outcome**: Parallel exploration paths with preserved history

### Tip 13: Reinforce Core Elements in Every Prompt

**Purpose**: "To prevent the AI from forgetting what's important, gently remind it of the non-negotiable elements in every follow-up prompt"

**Bad Example**: "change her shirt to red"

**Good Example**: "keep the character's facial structure and hairstyle identical, but change her shirt to a red jacket"

**Principle**: "This constantly reinforces your key constraints and reduces unwanted changes"

**Prerequisites**: Identifying core immutable elements

**Expected Outcome**: Maintained consistency across iterative edits

### Tip 14: Create a Digital Character Sheet

**Purpose**: Establish visual anchor for character consistency

**Workflow**:
1. "generating one perfect highquality front-facing portrait of your character. This is your master reference"
2. "Upload that master portrait and prompt nano banana. Create side and back views for this character in separate images"

**Result**: "This collection of orthogonal views is your character sheet. It gives you consistent visual data of your character from every angle for all future generations"

**Prerequisites**: Understanding of orthogonal views, character design

**Expected Outcome**: Comprehensive character reference for all angles

### Tip 15: Use Multi-Image Reference for Poses

**Purpose**: Separate identity from action for better accuracy

**Workflow**:
- "Upload both your master character portrait for identity and a separate reference image for the pose or environment for context"

**Prompt Example**: "Make the character from image one adopt the sitting pose from image two"

**Principle**: "This separates the task of identity from the task of action, giving you way more accuracy"

**Prerequisites**: Character sheet, pose reference library

**Expected Outcome**: Character in new pose with preserved identity

### Tip 16: Use Explicit Identity Preservation Prompts

**Purpose**: Command model to maintain consistency

**Approach**: "Be direct"

**Examples**:
- "Keep the subject's identity, body proportions, and clothing consistent"
- "preserve our likeness, no distortion"

**Principle**: "This reinforces the primary goal"

**Prerequisites**: Understanding of critical identity features

**Expected Outcome**: Maintained character identity across generations

### Tip 17: Generate Controlled Variations (Emotion Sheets)

**Purpose**: Create narrative variations while locking core identity

**Prompt Example**: "Using the character from the uploaded image, create an emotion sheet showing expressions for happy, sad, angry, and surprised"

**Additional Uses**: "This can also be used to show the character aging or in different states all while locking their core identity"

**Prerequisites**: Master character portrait

**Expected Outcome**: Emotional range or state variations with consistent identity

### Tip 18: Isolate Your Subject First

**Purpose**: Prevent AI confusion from competing details

**Two-Step Process**:
1. "Place this character on a clean white background" - creates clean asset
2. Use clean asset + background image to composite final scene

**Principle**: "This two-step process stops the AI from getting confused by competing details"

**Prerequisites**: Understanding of layer-based workflow

**Expected Outcome**: Cleaner character integration into complex scenes

### Tip 19: Use Multi-Image Fusion for Group Shots

**Purpose**: Place multiple consistent characters in one scene

**Workflow**: "Upload the master portraits for each one"

**Prompt Example**: "Create a new image showing the person from image one and the person from image two having a conversation at a cafe table"

**Prerequisites**: Master portraits for each character

**Expected Outcome**: Group scene with all characters maintaining identity

### Tip 20: Standardize Your Character Block

**Purpose**: Reinforce character identity through text consistency

**Character Block Example**: "A man with short brown hair, a prominent scar over his left eye, and blue eyes"

**Workflow**: "Include this exact block of text in every single prompt when generating new images of that character to constantly reinforce their identity"

**Prerequisites**: Defined character features document

**Expected Outcome**: Text-reinforced character consistency

### Tip 21: Establish an Environmental Master Shot

**Purpose**: Ensure visual continuity for locations

**Workflow**: "Before making a sequence, create one perfect establishing shot that defines the location's lighting, color grade, and mood"

**Usage**: "Use this image as a style reference for all subsequent shots in that location to ensure total visual continuity"

**Prerequisites**: Location design planning

**Expected Outcome**: Consistent environmental aesthetics across sequence

### Tip 22: Generate Consistent Props as Isolated Assets

**Purpose**: Ensure identical prop appearance across scenes

**Workflow**:
1. "First, generate a clean image of that prop on a neutral background. This is your reusable digital asset"
2. "Then use multi-image fusion to place that specific prop into different scenes or into your character's hands, ensuring it looks identical every time"

**Example Use**: "Need to use the same futuristic sword or branded product in multiple scenes?"

**Prerequisites**: Understanding of asset-based workflow

**Expected Outcome**: Identical prop across all scenes

### Tip 23: Translate Script Directly to Storyboard

**Purpose**: Build visually coherent storyboard from narrative

**Workflow**: "Take your script or shot list. For every key moment, use Nano Banana along with your established character and location master shots to generate the corresponding visual frame"

**Result**: "You can build an entire visually coherent storyboard that matches your narrative perfectly"

**Prerequisites**: Complete script/shot list, character and location masters

**Expected Outcome**: Full visual storyboard with narrative consistency

### Tip 24: The Core Animation Pipeline

**Purpose**: Fundamental workflow for AI video creation

**Pipeline**: "nano banana for consistent key frames, AI video model for animation"

**Detailed Workflow**:
1. "You generate your perfect consistent storyboard panels in nano"
2. "Then export them and import them into a tool like Google V3, Lumad Dream Machine or Runway to generate the motion between those shots"

**Prerequisites**: Nano Banana mastery, access to video AI tools

**Expected Outcome**: Animated sequences from static storyboards

### Tip 25: The Start-End Frame Technique

**Purpose**: Precise motion control for complex actions

**Workflow**:
1. "generate your starting shot frame A and your desired ending shot frame B using Nano Banana"
2. "upload both images to a video model that supports this, like cling or Hiluo"
3. "You prompt the video model to create the transition between them"

**Example Use**: "incredibly powerful for complex actions like a character running to and climbing into a car"

**Prerequisites**: Nano Banana for frames, video model with start-end support

**Expected Outcome**: Controlled transition between precise keyframes

### Tip 26: Generate In-Between Frames (Tweens)

**Purpose**: Smooth transitions when jump is too large

**Problem**: "What if your video model struggles to make a smooth jump between two very different key frames, like a character standing frame A and then sitting frame C? The jump is too big"

**Fix**: "use Nano Banana to generate one or two in between frames or twins that break the action down further. Create a shot of the character beginning to sit frame B"

**Result**: "Animating from A to B and then B to C is far more successful than a direct jump from A to C"

**Prerequisites**: Identifying large transition gaps

**Expected Outcome**: Smoother animated transitions

### Tip 27: The Midjourney to Nano Banana Pipeline

**Purpose**: Combine creative ideation with production consistency

**Official Status**: "the single most effective hybrid workflow used by the creative AI community"

**Three-Step Workflow**:

**Step 1 - Ideation in Midjourney**: "Use midjourney for your initial concept generation. Its strength is pure artistry, imagination, and unique style. Perfect for finding your creative direction"

**Step 2 - Consistency in Nano Banana**: "Once you have your perfect midjourney image, import it into Nano Banana. This now becomes your master reference"

**Step 3 - Expansion in Nano Banana**: "Leverage Nano Banana's superior consistency engine to generate all your variations, different camera angles, character sheets, emotion sheets, and insecene edits"

**Principle**: "This workflow combines MidJourney's Creative Spark with Nano Banana's productionready consistency"

**Prerequisites**: Access to both Midjourney and Nano Banana

**Expected Outcome**: Creative excellence with production consistency

### Tip 28: Use LLMs for Prompt Engineering

**Purpose**: Leverage AI to craft better prompts

**Workflow**: "Before you even touch Nano Banana, use a powerful LLM like GPT4 or Claude to brainstorm your prompts. Give the LLM your simple idea and ask it to generate a detailed technical prompt using all the cinematic and photographic language we discussed previously"

**Effect**: "This effectively turns the LLM into your creative director, crafting the perfect instructions for you"

**Prerequisites**: Access to GPT-4 or Claude, understanding of prompt structure

**Expected Outcome**: Professional-grade prompts from simple ideas

### Tip 29: Fixing Aspect Ratio

**Purpose**: Overcome Nano Banana's square default limitation

**Problem**: "Nano Banana ignores dimension prompts and defaults to a square"

**Principle**: "Fighting this is a waste of time"

**Fix Workflow**:
1. "first go to a design platform like Canva. Get a background in your desired dimension. The background should be in white plain color"
2. "download this background from Canva. Upload it to Nano Banana"
3. "Then use this prompt. Use the image only for reference ratio size. Create a new image of desired image here"

**Alternative**: "import an image with the dimensions you wish to use. Tell it to generated your image while placing it on the dimension of the uploaded image"

**Prerequisites**: Access to Canva or similar design tool

**Expected Outcome**: Images in desired aspect ratio

### Tip 30: Fixing Poor Style Transfer with Image-Based Prompts

**Purpose**: Overcome weak text-based style interpretation

**Problem**: "Nano Banana is terrible at interpreting textbased style prompts. Prompts like in the style of Van Gogh or in the style of Picasso simply do not work well"

**Rule**: "never rely on text for critical style transfer tasks"

**Fix Workflow**:
1. "upload your content image, image A"
2. "upload a second image that is a perfect example of the artistic style you want, image B"
3. "use a prompt that tells the model exactly what to do with this visual data"

**Prompt Example**: "apply the artistic style, color palette, and texture of image B to the composition of image A"

**Principle**: "This uses direct visual analysis, not abstract text, and gives you vastly superior and more predictable results"

**Prerequisites**: Style reference images, multi-image upload capability

**Expected Outcome**: Accurate style transfer matching reference

## Facts & Evidence

### Tool Capabilities
- Character consistency: "creating incredible 3D figurines and keeping your character identical across dozens of images"
- Training data: "It was trained on millions of photos with all their technical metadata"
- Official name: "Gemini 2.5 Flash Image"
- Nickname: "Nano Banana"
- Key strength: "Nano Banana is famous for this" (long-form consistency)

### Known Limitations
- "massive loss in image resolution"
- "A stubborn refusal to control aspect ratios"
- "weak prompt adherence"
- "an over-the-top censorship system that blocks totally safe creative requests"
- "defaults to a square" for aspect ratio
- Style transfer: "Prompts like in the style of Van Gogh or in the style of Picasso simply do not work well"

### Comparison to Traditional Methods
- LoRA training: "Normally, you'd have to train a custom Laura model on dozens of images to get character consistency. Nano Banana does it instantly from a single reference image"

### Video AI Tools Mentioned
- Google Veo 3
- Luma Dream Machine
- Runway
- Kling (supports start-end frame technique)
- Hailuo (supports start-end frame technique)

### Prompt Engineering Tools
- GPT-4
- Claude

### Design Tools
- Canva (for aspect ratio workaround)
- Photoshop (for outpainting)

### Consistency Drift Timeline
- "after three or four edits" - when quality degradation becomes noticeable

## Expert Insights

### On Tool Philosophy
- **Core Principle**: "Stop fighting the tool. Stop treating it like a broken all-in-one generator. Embrace it for what it truly is, the most powerful high-speed consistency engine we have ever had access to"
- **Context**: Reframing Nano Banana's purpose changes how you use it
- **Implication**: Workflow design must account for tool specialization

### On Prompting Precision
- **Principle**: "using that technical language isn't a suggestion. It's a coordinate pointing the model directly to the visuals you want"
- **Effect**: "This is how we stop the model from interpreting and start making it execute"
- **Implication**: Technical precision = execution control, vagueness = interpretation variance

### On Multi-Tool Workflows
- **Vision**: "The future of AI art isn't one perfect tool. It's the curated AI toolkit, and it's mastering the art of making many tools work as one"
- **Strategy**: "build an intelligent hybrid tool chain around it. Combining its consistency with Midjourney's creativity and Photoshop's outpainting"
- **Implication**: Professional results require understanding tool strengths and building pipelines

### On Design Trade-offs
- **Engineering Choice**: "What if I told you that its biggest problem isn't a bug, it's a deliberate engineering choice?"
- **Explanation**: "This tool was optimized for speed, efficiency, and mobile users. It prioritizes rapid generation over maximum fidelity"
- **Implication**: Understanding design goals prevents misuse and frustration

### On Workflow Transformation
- **Transformation**: "That is when you transform it from a frustrating toy into an indispensable professional asset"
- **Prerequisites**: "When you prompt it with the precision of a cinematographer, manage its iteration to preserve fidelity. And most importantly, build an intelligent hybrid tool chain around it"
- **Implication**: Mastery comes from systematic approach, not just tool access

### On Negative Prompting
- **Official Guidance**: "recommended directly by Google's own guides"
- **Issue**: "Nano Banana gets confused by negative commands"
- **Solution**: Affirmative description of desired state
- **Implication**: Model architecture limitation requires prompt adaptation

### On Iterative Editing
- **Best Practice**: "This atomic approach is a core best practice"
- **Context**: Single-purpose edits vs. multi-change prompts
- **Implication**: Patience in workflow = better results

### On Midjourney + Nano Banana Synergy
- **Status**: "the single most effective hybrid workflow used by the creative AI community"
- **Strength Distribution**: Midjourney for creativity, Nano Banana for consistency
- **Implication**: Tool combination unlocks capabilities neither has alone

## Warnings & Pitfalls

### Using Vague Descriptive Language
- **Mistake**: "prompting Nano Banana with simple descriptive language"
- **Example**: "blurry background" instead of technical specification
- **Why It Fails**: Ambiguity leads to interpretation variance
- **Fix**: Use technical camera/lens specifications

### Multiple Changes in Single Prompt
- **Mistake**: "Never ever try to change multiple complex things in one prompt"
- **Bad Example**: "Change the background to a beach. Make her smile and adjust the lighting to sunset"
- **Why It Fails**: "The model will get overwhelmed and give you a blended low-quality mess"
- **Fix**: Sequential single-purpose edits (Tip 10)

### Ignoring Consistency Drift
- **Problem**: Continuing edits without resetting causes progressive quality loss
- **Symptom**: "image quality degrade as artifacts build up"
- **Timeline**: Noticeable "after three or four edits"
- **Fix**: Execute fidelity reset (Tip 11)

### Using Negative Commands
- **Mistake**: Prompts like "no cars" or "no rain"
- **Why It Fails**: "Nano Banana gets confused by negative commands"
- **Official Source**: Google's own guides warn against this
- **Fix**: Use semantic positive prompting (Tip 5)

### Complex Background + Character Simultaneously
- **Problem**: Generating character in complex scene in one shot
- **Why It Fails**: "stops the AI from getting confused by competing details"
- **Fix**: Two-step isolation (Tip 18) - neutral background first, then composite

### Text-Based Style Transfer
- **Mistake**: "Prompts like in the style of Van Gogh or in the style of Picasso"
- **Why It Fails**: "Nano Banana is terrible at interpreting textbased style prompts. Prompts like in the style of Van Gogh or in the style of Picasso simply do not work well"
- **Rule**: "never rely on text for critical style transfer tasks"
- **Fix**: Use image-based style reference (Tip 30)

### Fighting Aspect Ratio with Text Prompts
- **Mistake**: Trying to use dimension prompts
- **Why It Fails**: "Nano Banana ignores dimension prompts and defaults to a square"
- **Principle**: "Fighting this is a waste of time"
- **Fix**: Use background image with desired dimensions (Tip 29)

### Treating as All-in-One Tool
- **Mistake**: "Stop treating it like a broken all-in-one generator"
- **Expectation Problem**: Expecting professional-grade everything
- **Reality**: "highly specialized, high-speed consistency engine"
- **Fix**: Build hybrid workflows around its specific strength

### Large Keyframe Jumps in Animation
- **Problem**: "What if your video model struggles to make a smooth jump between two very different key frames"
- **Example**: Standing (frame A) directly to sitting (frame C)
- **Why It Fails**: "The jump is too big"
- **Fix**: Generate in-between frames (Tip 26)

### Forgetting Core Elements in Iterative Edits
- **Problem**: "To prevent the AI from forgetting what's important"
- **Symptom**: Unintended changes to key features
- **Fix**: Reinforce core elements in every prompt (Tip 13)

## Examples

### Example 1: Master Prompt Template (Complete)

**Full Template**:
"a photorealistic [shot type] of [subject] captured with a [camera lens details]. The scene is illuminated by [lighting description] creating a [mood/atmosphere] in the style of [film genre]. The color palette is [color description] with a focus on [key textures]"

**Concrete Example** (inferred from components):
"a photorealistic close-up 3/4 portrait of a warrior captured with an 85mm portrait lens at f1.8. The scene is illuminated by soft golden hour light streaming through a window creating a warm heroic atmosphere in the style of film noir. The color palette is desaturated with warm color temperature with a focus on water droplets on skin and intricate armor panels"

**Components Used**: Tips 1-8 combined

### Example 2: Semantic Positive Prompting

**Bad Prompt**: "a street with no cars"
**Good Prompt**: "An empty deserted street with no signs of traffic"

**Difference**: Negative instruction ("no cars") replaced with affirmative description ("empty deserted street with no signs of traffic")

**Lesson**: Model processes positive descriptions more reliably

### Example 3: Incremental Editing Workflow

**Bad Single Prompt**: "Change the background to a beach. Make her smile and adjust the lighting to sunset"

**Good Sequential Workflow**:
1. Prompt 1: "Change the background to a beautiful beach"
2. Prompt 2: "Now make her smile naturally"
3. Prompt 3: "Finally, adjust the lighting to a warm sunset golden hour"

**Lesson**: Breaking complexity into atomic steps prevents quality loss

### Example 4: Multi-Image Pose Reference

**Scenario**: Character needs specific sitting pose

**Workflow**: Upload character portrait + sitting pose reference

**Prompt**: "Make the character from image one adopt the sitting pose from image two"

**Lesson**: Separating identity from action increases accuracy

### Example 5: Emotion Sheet Generation

**Starting Point**: Master character portrait uploaded

**Prompt**: "Using the character from the uploaded image, create an emotion sheet showing expressions for happy, sad, angry, and surprised"

**Result**: Four variations with identical character, different emotions

**Lesson**: Master reference enables controlled variations

### Example 6: Midjourney to Nano Banana Pipeline

**Step 1 (Midjourney)**: Generate unique creative concept - e.g., cyberpunk samurai with unique artistic style

**Step 2 (Import to Nano)**: Midjourney image becomes master reference in Nano Banana

**Step 3 (Expand in Nano)**: Generate:
- Character sheet (front, side, back views)
- Emotion sheet
- Different camera angles
- Scene variations

**Lesson**: Combines Midjourney's creativity with Nano's consistency

### Example 7: Aspect Ratio Fix via Canva

**Problem**: Need 16:9 landscape image, Nano generates square

**Solution**:
1. Create white 16:9 background in Canva
2. Download and upload to Nano Banana
3. Prompt: "Use the image only for reference ratio size. Create a new image of [desired subject]"

**Result**: Image generated in 16:9 format

**Lesson**: Use visual dimension reference instead of text instructions

### Example 8: Style Transfer Fix

**Bad Approach**: Text prompt "in the style of Van Gogh"
**Result**: Unpredictable or poor style match

**Good Approach**:
1. Upload content image (your subject)
2. Upload Van Gogh painting as style reference
3. Prompt: "apply the artistic style, color palette, and texture of image B to the composition of image A"

**Result**: Accurate Van Gogh-style rendering

**Lesson**: Visual style reference vastly outperforms text description

### Example 9: Character Block Standardization

**Character Block**: "A man with short brown hair, a prominent scar over his left eye, and blue eyes"

**Usage**: Include this exact text in every prompt for that character:
- "A man with short brown hair, a prominent scar over his left eye, and blue eyes standing on a rooftop"
- "A man with short brown hair, a prominent scar over his left eye, and blue eyes sitting at a cafe"

**Lesson**: Text reinforcement adds consistency layer to visual reference

### Example 10: In-Between Frame (Tween) for Animation

**Problem**: Character standing (Frame A) â†’ Character sitting (Frame C) is too large a jump

**Solution**:
1. Generate Frame A: Character standing
2. Generate Frame B: Character beginning to sit (in-between)
3. Generate Frame C: Character fully seated
4. Animate Aâ†’B, then Bâ†’C

**Result**: Smoother animation than direct Aâ†’C jump

**Lesson**: Breaking large transitions into smaller steps improves animation quality

## Knowledge Gaps

- [FLAG: Censorship system details] - "an over-the-top censorship system that blocks totally safe creative requests"
  - Missing: What specific content triggers censorship, how to appeal or work around

- [FLAG: Resolution loss specifics] - "massive loss in image resolution"
  - Missing: Actual resolution numbers, comparison to other tools, whether resolution can be preserved

- [FLAG: Temporary implicit model duration] - "this model is temporary and can be corrupted by new prompts"
  - Missing: How long the implicit model persists, what corrupts it specifically

- [FLAG: Fidelity reset frequency] - "After a long chain of edits"
  - Missing: Specific number of edits before reset recommended, metrics to watch

- [FLAG: Multi-image upload limits] - Mentioned for group shots, style transfer, poses
  - Missing: Maximum number of images that can be uploaded simultaneously

- [FLAG: Video model support details] - "a video model that supports this, like cling or Hiluo"
  - Missing: Which specific features each video model supports, cost comparison

- [FLAG: Canva background specifications] - "background should be in white plain color"
  - Missing: Why white specifically, whether other colors work, resolution requirements

- [FLAG: GPT-4 vs Claude for prompting] - "use a powerful LLM like GPT4 or Claude"
  - Missing: Which performs better for this task, specific prompt structure to ask them

- [FLAG: Google's official guides] - "recommended directly by Google's own guides"
  - Missing: URL or reference to these official guides for semantic positive prompting

- [FLAG: Photoshop outpainting integration] - Mentioned but not detailed
  - Missing: Specific workflow for Nano Banana + Photoshop outpainting pipeline

## Verification Notes
- **Total substantive segments**: 30 complete tips extracted with detailed workflows
- **Confidence level**: High - systematic tutorial structure with clear examples
- **Transcript quality**: User-provided, appears complete
- **Completeness**: Full - all 30 tips covered comprehensively

---

## Full Transcript

[Music] What is up creators and welcome to AI in action. Here are 30 expert techniques to help you master Google's Gemini 2.5 flash image, better known as Nano Banana.

[Full transcript continues as provided in original...]
